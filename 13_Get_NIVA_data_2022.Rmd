---
title: "Get NIVA trends, 2022 (data unitl ?)"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
    
---

Actually the script should be called get NIVA _trends_ because that is what we actually do   

NOTE:  
* This script is used for both '2021 North Sea' and '2021 Norwegian Sea' - set 'area' to the right ocean!    


## Packages + functions  
```{r, results='hide', message=FALSE}

library(dplyr)
library(tidyr)
library(readxl)
library(ggplot2)
library(purrr)

# for JAGS
library(R2jags)
library(rjags)
source("interval_lm_qi.R")  # function 'int_linear_qi'  

```

### Year  
```{r}

year_2020_data <- TRUE

```



### Area
```{r}

# area <- "North_Sea"
area <- "Norwegian_Sea"

```


## Data

### Checking stations and parameters for 2020 assessment

```{r}
#
# Checking stations and parameters for 2020 assessment
# _______________________________________________________________________________________only exists as csv...
## does not exist in folder
df_indicator_2021 <- readRDS("Input_data/NIVA_data_2022-09-01.rds") # 

tab1 <- xtabs(~STATION_CODE + LATIN_NAME, df_indicator_2021)
tab2 <- xtabs(~PARAM + LATIN_NAME, df_indicator_2021)
tab1
# STATION_CODE Gadus morhua Mytilus edulis
# 10A2            0              6
# 10B             6              0
# 11X             0              6
# 19B             5              0
# 43B2            5              0
# 45B2            4              0
# 98A2            0              5
# 98B1            7              0

tab2
rownames(tab2)

```


### 'data_xl_sel' = selected rows of excel table
```{r}


### 
# Latest NIVA data ----
#

# dat_all <- readRDS("../Milkys2_pc/Files_from_Jupyterhub_2021/Raw_data/101_data_updated_2022-09-01.rds") %>%
#   select(MYEAR:VALUE_WW)
# saveRDS(dat_all, "Input_data/NIVA_data_2022-09-01.rds")

dat_all <- readRDS("Input_data/NIVA_data_2022-09-01.rds")

dat_1a <- dat_all %>%
  filter(
    STATION_CODE %in% c("10A2", "10B", "11X", "19B", "43B2", "45B2", "98A2", "98B1", "20B"),
    PARAM %in% c("CD", "DDEPP", "HCB", "HG", "PB")
  )

xtabs(~PARAM + STATION_CODE, dat_1a)

#
# NOTE: ADD station 20B as well
#

#
# Calculate upper/lower bounds of PCB7 ----
#

dat_1b <- dat_all %>%
  filter(
    STATION_CODE %in% c("10A2", "10B", "11X", "19B", "43B2", "45B2", "98A2", "98B1", "20B"),
    PARAM %in% c("CB28", "CB52", "CB101", "CB118", "CB138", "CB153", "CB180")  # for BDE, replace here 
  ) %>%
  mutate(
    VALUE_lo = ifelse(is.na(FLAG1), VALUE_WW, 0),
    VALUE_up = VALUE_WW
  ) %>%
  group_by(STATION_CODE, SAMPLE_NO2, LATIN_NAME, MYEAR) %>%
  summarise(
    CB7_lo = sum(VALUE_lo),
    CB7_up = sum(VALUE_up)
  )

# Medians of lower and upper bound
dat_1b_median <- dat_1b %>%
  group_by(STATION_CODE, LATIN_NAME, MYEAR) %>%
  summarise(
    CB7_lo = median(CB7_lo),
    CB7_up = median(CB7_up)
  )


#
# Get sumPCB7 data for one station  
#

#
# . Individual data ----
#
dat_test1 <- dat_1b %>%
  filter(STATION_CODE == "10A2")

ggplot(dat_test1, aes(x = MYEAR)) +
  geom_point(aes(y = CB7_up), color = "red") +
  geom_point(aes(y = CB7_lo), color = "blue")

#
# . Median data ----
#
dat_test2 <- dat_1b_median %>%
  filter(STATION_CODE == "10A2")

ggplot(dat_test2, aes(x = MYEAR)) +
  geom_point(aes(y = CB7_up), color = "red") +
  geom_point(aes(y = CB7_lo), color = "blue")



#
# Interval regression using 'icenReg' ----   
#
# - NOTE: will not be used
# 

# install.packages("icenReg")
library(icenReg)
library(foreach)
library(doParallel)

# using individual datat  
mle_fit <- ic_par(cbind(CB7_lo, CB7_up) ~ MYEAR,
                  model = "ph",
                  dist = "lnorm",
                  data = dat_test1)
summary(mle_fit)


#
# Interval regression using JAGS function ----   
#

library(R2jags)
library(rjags)

source("interval_lm_qi.R")  # function 'int_linear_qi'  

#
# . all data (until 2021) ----      
#


# Model
mod <- int_linear_qi(data = dat_test2, x = "MYEAR", y_lo = "CB7_lo", y_up = "CB7_up")

# str(mod,1)

cat("Estimate of slope (with uncertainty) \n")
mod$slope

if (mod$slope[["2.5%"]] > 0){
  # If lower range (2.5 percentile) of the slope estimate is above zero....
  cat("Significant increase over time")
} else if (mod$slope[["97.5%"]] < 0){
  # If upper range (97.5 percentile) of the slope estimate is below zero....
  cat("Significant decrease over time")
} else {
  cat("No significant change over time")
}

# Test plot  
ggplot(dat_test2, aes(x = MYEAR)) +
  geom_point(aes(y = CB7_up), color = "red") +
  geom_point(aes(y = CB7_lo), color = "blue") +
  geom_line(data = mod$plot_data, aes(x, y)) +
  geom_line(data = mod$plot_data, aes(x, y_lo), linetype = "dashed") +
  geom_line(data = mod$plot_data, aes(x, y_hi), linetype = "dashed")



#
# . shorter time series (until 2014) ----      
#

dat_test2b <- dat_test2 %>% filter(MYEAR <= 2016)

# Model
mod <- int_linear_qi(data = dat_test2b, x = "MYEAR", y_lo = "CB7_lo", y_up = "CB7_up")

# str(mod,1)

cat("Estimate of slope (with uncertainty) \n")
mod$slope


# Test plot  
ggplot(dat_test2b, aes(x = MYEAR)) +
  geom_point(aes(y = CB7_up), color = "red") +
  geom_point(aes(y = CB7_lo), color = "blue") +
  geom_line(data = mod$plot_data, aes(x, y)) +
  geom_line(data = mod$plot_data, aes(x, y_lo), linetype = "dashed") +
  geom_line(data = mod$plot_data, aes(x, y_hi), linetype = "dashed")
```
```{r}
#
# Interval regression for several time series ----   
#

#
# . data ----
#
# Standardize on names VALUE_lo and VALUE_up
#

dat_individual_param <- dat_all %>%
  filter(
    STATION_CODE %in% c("10A2", "10B", "11X", "19B", "43B2", "45B2", "98A2", "98B1", "20B"),
    PARAM %in% c("CD", "DDEPP", "HCB", "HG", "PB")  
  ) %>%
  mutate(
    VALUE_lo = ifelse(is.na(FLAG1), VALUE_WW, 0),
    VALUE_up = VALUE_WW
  ) %>%
  select(STATION_CODE, SAMPLE_NO2, MYEAR, PARAM, VALUE_lo, VALUE_up)


# data for PCB sum  
# Almost identical to 'dat_1b' code above, but setting names to VALUE_lo and VALUE_up,
# and adding PARAM = "CB_S7"

dat_CB <- dat_all %>%
  filter(
    STATION_CODE %in% c("10A2", "10B", "11X", "19B", "43B2", "45B2", "98A2", "98B1", "20B"),
    PARAM %in% c("CB28", "CB52", "CB101", "CB118", "CB138", "CB153", "CB180")  # for BDE, replace here 
  ) %>%
  mutate(
    VALUE_lo = ifelse(is.na(FLAG1), VALUE_WW, 0),
    VALUE_up = VALUE_WW
  ) %>%
  group_by(STATION_CODE, SAMPLE_NO2, LATIN_NAME, MYEAR) %>%
  summarise(
    VALUE_lo = sum(VALUE_lo),
    VALUE_up = sum(VALUE_up), .groups = "drop",
  ) %>%
  mutate(PARAM = "CB_S7") %>%
  select(STATION_CODE, SAMPLE_NO2, MYEAR, PARAM, VALUE_lo, VALUE_up)


# NOTE: for BDE, make a similar 'dat_BDE' where PARAM = BDE6S
#   and the sum is defined like this:
# BDE6S = Sum of BDE congener numbers 28 (tri), 47 (tetra), 99 (penta), 
#   100 (penta), 153 (hexa) and 154 (hexa)
# Names: BDE28, BDE47 etc.


dat_BDE <- dat_all %>%
  filter(
    STATION_CODE %in% c("10A2", "10B", "11X", "19B", "43B2", "45B2", "98A2", "98B1", "20B"),
    PARAM %in% c("BDE100", "BDE119", "BDE126", "BDE138", "BDE153", "BDE154", "BDE156", "BDE17", "BDE183", "BDE184", "BDE191",
                 "BDE196", "BDE197", "BDE202", "BDE205", "BDE206", "BDE207", "BDE209", "BDE28", "BDE47", "BDE49", "BDE66",
                 "BDE6S", "BDE71", "BDE77", "BDE85", "BDE99", "BDESS")  # for BDE, replace here 
  ) %>%
  mutate(
    VALUE_lo = ifelse(is.na(FLAG1), VALUE_WW, 0),
    VALUE_up = VALUE_WW
  ) %>%
  group_by(STATION_CODE, SAMPLE_NO2, LATIN_NAME, MYEAR) %>%
  summarise(
    VALUE_lo = sum(VALUE_lo),
    VALUE_up = sum(VALUE_up), .groups = "drop",
  ) %>%
  mutate(PARAM = "CB_S7") %>%
  select(STATION_CODE, SAMPLE_NO2, MYEAR, PARAM, VALUE_lo, VALUE_up)






# bind rows of CB, BDE and others
dat_test3_individual <- bind_rows(
  dat_individual_param,
  dat_CB,                     
  dat_BDE
)

dat_test3_medians <- dat_test3_individual %>%
  group_by(PARAM, STATION_CODE, MYEAR) %>%
  summarise(
    VALUE_lo = median(VALUE_lo),
    VALUE_up = median(VALUE_up)
  )



# Here, two time series for CB7: stations 45B2 and 98A2


# Make function that returns a data frame with lower and upper limits of the slope
#   for a given function and for a given data set
# (Can modify this so it also works for a specific parameter, but in this case we usi)
get_trendslope <- function(parameter, stationcode, data){
  dat_selected <- data %>%
    filter(PARAM %in% parameter & STATION_CODE %in% stationcode)
  mod <- int_linear_qi(data = dat_selected, x = "MYEAR", y_lo = "VALUE_lo", y_up = "VALUE_up")
  data.frame(
    PARAM = parameter,
    STATION_CODE = stationcode,
    slope_lo = mod$slope[["2.5%"]],
    slope = mod$slope[["50%"]],
    slope_up = mod$slope[["97.5%"]])
}




# test for one parameter / station
X <- get_trendslope("CB_S7", "10A2", dat_test3_medians)
# X

# Make "safe" version (doen't stop if there is an error)
get_trendslope_s <- safely(get_trendslope)

X2 <- get_trendslope_s("CB_S7", "10A2", dat_test3_medians)

# result1 <- map2(c("CB_S7","CB_S7", "PB"), c("10A2","43B2", "10A2"), get_trendslope_s, data = dat_test3_medians)

# Get all combinations:
df_combinations <- dat_test3_medians %>%
  distinct(PARAM, STATION_CODE)
result1 <- map2(df_combinations$PARAM, df_combinations$STATION_CODE, get_trendslope_s, data = dat_test3_medians)

# example
result1[[3]]$result

str(result1, 1)
str(result1, 2)

# collecting the results  
result2 <- purrr::transpose(result1)
result_is_ok <- map_lgl(result2$error, is.null) 
result3 <- result2$result[result_is_ok]

result4 <- bind_rows(result3)

result4 <- result4 %>%
  mutate(
    trend = case_when(
      slope_lo > 0 ~ 2,
      slope_up < 0 ~ 3,
      TRUE ~ 1),
    trend_text = case_when(
      slope_lo > 0 ~ "Trend_up",
      slope_up < 0 ~ "Trend_down",
      TRUE ~ "No trend")
  )



```
### Station data  
Shortened from script 98 in 'Milkys'   
```{r}

# Origin of data. Kept here only for reference.
# data_stations <- readxl::read_excel("../Milkys2_pc/Files_to_Jupyterhub_2019/Kartbase_edit.xlsx") %>%
#   rename(LATITUDE = Lat, LONGITUDE = Long, 
#          STATION_NAME = Station_name) %>%
#   filter(!is.na(STATION_CODE))
# saveRDS(data_stations, "Input_data/NIVA_data_stations.rds")
         
data_stations <- readRDS("Input_data/NIVA_data_stations.rds")         

```


### Limits
```{r}
# Limits for EQS and Mattrygghet (food safety)
df_limits <- read_excel("Input_data/Grenseverdier_fra_Sylvia.xlsx")

```

## Add Conc value for check  
- Concnetration value of last year  
- If less-than, it is set slightly lower than value (in case the limit is exacly the same)
- To remove before export
```{r}

dat_last_year <- dat_all %>%
  filter(MYEAR == 2022) %>%
  left_join( ....  add df_limits using by= PARAM name ....) # not sure what df is this connected to?


# then compare VALUE_WW with limit


```

### Trends

```{r}

# For metals, use lm() of VALUE_WW against MYEAR

# For sum PCB and sum BDE, make lower and upper bound and use int_linear_qi()   
# Sum BDE = sum of BDE28, 47, 99, 100, 126, 153, 154, 183, 196 and 209

# Shall end up with 'trend' codes 0 to 3
#  trend_text = c("Too little data", "Too few data above LOQ", "No trend", "Trend up", "Trend down"),
#  trend = c(0,0,1,2,3)

# Too little data is defined as <5 years  

```



### For checking  

```{r}

if (FALSE){
  
  data_xl %>% 
    filter(`Parameter Code` == "HG" & Basis == "WW" & `Station Code` == "43B2") %>%
    select(`Parameter Code`, Basis, `Station Code`, `Station Name`, PROREF, V19, V20)
  
  # Don't need Basis == "WW" - taht has been selected already
  data_xl_sel %>%
    filter(`Parameter Code` == "HG" & `Station Code` == "43B2") %>%
    select(`Parameter Code`, Basis, `Station Code`, `Station Name`, PROREF, V19, V20, Conc_for_check)
  
}

```


## 'df_indicator'  

### Make 'df_indicator'  
```{r}

df_indicator <- tibble(
  PROJECT_ID = 3699,
  LATIN_NAME = data_xl_sel[["Species"]],
  STATION_CODE = data_xl_sel[["Station Code"]],
  SPECIES_ID = 17,                  # HARD-CODED - check above that we only have cod stations
  TISSUE_NAME = data_xl_sel[["Tissue"]],
  PARAM = data_xl_sel[["Parameter Code"]],
  Conc = data_xl_sel[["Conc_for_check"]],
  # SKIP THIS:
  trend_symbol = substr(data_xl_sel$`Trends this year`, 3, 3),     # 3rd symbol, e.g. the "¢" in ê/¢ - FOR 10-YEAR TREND
  N = NA
  )

#
# Add station position + name
#
nrow(df_indicator)  # 275
df_indicator <- df_indicator %>% 
  inner_join(data_stations, by = "STATION_CODE")
nrow(df_indicator)  # 44


```


### Add NIVA_CODE
```{r}

df_tissue_code <- tibble(
  TISSUE_NAME = c("Whole soft body", "Muscle", "Liver"),
  NIVA_CODE = c("SB","MU","LI")
  )

nrow(df_indicator)
df_indicator <- left_join(df_indicator, df_tissue_code, by = "TISSUE_NAME")
nrow(df_indicator)

```

### Add trend text
```{r}

# Check 'set_symbol' function: 
# source("18_Time_series_write_to_Excel_functions.R")
# set_symbol
df_symbol_to_trend <- tibble(
  trend_symbol = c("§", "«", "¢", "é", "ê"),  
  trend_text = c("Too little data", "Too few data above LOQ", "No trend", "Trend up", "Trend down"),
  trend = c(0,0,1,2,3)
  )

# Add trend symbol  
nrow(df_indicator)
df_indicator <- left_join(df_indicator, df_symbol_to_trend, by = "trend_symbol")
nrow(df_indicator)

# Check result
table(addNA(df_indicator$trend))

df_indicator$trend_symbol <- NULL
df_indicator$trend_text <- NULL

head(df_indicator, 3)

```

## Save  
```{r}
### new output 
overwrite <- FALSE
# overwrite <- TRUE

if (overwrite){
  
  if (area == "North_Sea"){
    
    # Save indicator for NIVA data
    saveRDS(df_indicator, "Data/13_df_indicator_NIVA_only (2022).rds")
    write.csv(df_indicator, "Data/13_df_indicator_NIVA_only (2022).csv", 
              quote = FALSE, row.names = FALSE)
    
    # Save selected excel data
    saveRDS(data_xl_sel, "Data/13_data_xl_sel (2022).rds")
    
    
  } else if (area == "Norwegian_Sea"){

    # file.copy("Data/13_df_indicator_NIVA_only (2021_NorwSea).rds", "Data/13_df_indicator_NIVA_only (2021_NorwSea)_OUTDATED.rds")
    
    # Save indicator for NIVA data
    saveRDS(df_indicator, "Data/13_df_indicator_NIVA_only (2022).rds")
    write.csv(df_indicator, "Data/13_df_indicator_NIVA_only (2022).csv", 
              quote = FALSE, row.names = FALSE)
    
    # Save selected excel data
    saveRDS(data_xl_sel, "Data/13_data_xl_sel (2021_NorwSea).rds")
    
  }
  
}

if (FALSE) {
  
  df_indicator <- readRDS("Data/13_df_indicator_NIVA_only (2022).rds")

  
}

```


## Compare with the outdated version  
```{r}

df_indicator_p <- readxl::read_excel("Data_export/GaduMor_2021data_Norw_Sea_ver03.xlsx")
# readRDS("Data/13_df_indicator_NIVA_only (2021_NorwSea)_OUTDATED.rds")
df_indicator <- readRDS("Data/13_df_indicator_NIVA_only (2021_NorwSea).rds")


if (FALSE){
  
  df_indicator_p %>% 
    filter(PARAM == "HG" & STATION_CODE == "43B2") %>%
    select(PARAM, STATION_CODE, KLASSE, trend, EQS, Mattrygghet)
  
  df_indicator %>% 
    filter(PARAM == "HG" & STATION_CODE == "43B2") %>%
    select(PARAM, STATION_CODE, trend)
  
  }

```



